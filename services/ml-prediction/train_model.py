#!/usr/bin/env python3
"""
ë¡œë˜ ë²ˆí˜¸ ì˜ˆì¸¡ ML ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì‹¤ì œ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Random Forest, XGBoost ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import sys
import os
import numpy as np
import pandas as pd
import pickle
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, accuracy_score
import xgboost as xgb

# ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(__file__))
from app.database import Database


class LottoModelTrainer:
    """ë¡œë˜ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨"""
    
    def __init__(self, db):
        self.db = db
        self.models_dir = './models'
        os.makedirs(self.models_dir, exist_ok=True)
        
        self.rf_models = {}  # ë²ˆí˜¸ ìœ„ì¹˜ë³„ Random Forest ëª¨ë¸
        self.xgb_models = {}  # ë²ˆí˜¸ ìœ„ì¹˜ë³„ XGBoost ëª¨ë¸
    
    def load_data(self, min_rounds=100):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  íšŒì°¨ ì¡°íšŒ
        data = self.db.get_all_numbers()
        
        if len(data) < min_rounds:
            print(f"âš ï¸  ê²½ê³ : ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (í˜„ì¬: {len(data)}ê°œ, ìµœì†Œ: {min_rounds}ê°œ)")
            print(f"   í¬ë¡¤ëŸ¬ë¡œ ë” ë§ì€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
            return None
        
        print(f"âœ“ {len(data)}ê°œ íšŒì°¨ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(data)
        df = df.sort_values('round')
        
        return df
    
    def extract_features(self, df, window=10):
        """íŠ¹ì„± ì¶”ì¶œ (Feature Engineering)"""
        print("\nğŸ”§ íŠ¹ì„± ì¶”ì¶œ ì¤‘...")
        
        features_list = []
        targets = {f'num{i+1}': [] for i in range(6)}
        
        for idx in range(window, len(df)):
            # ìµœê·¼ windowê°œ íšŒì°¨ ë°ì´í„°
            recent = df.iloc[idx-window:idx]
            
            # íŠ¹ì„± ê³„ì‚°
            features = {}
            
            # 1. ìµœê·¼ ë²ˆí˜¸ë“¤ì˜ ë¹ˆë„
            all_numbers = []
            for _, row in recent.iterrows():
                all_numbers.extend([
                    row['number1'], row['number2'], row['number3'],
                    row['number4'], row['number5'], row['number6']
                ])
            
            # ê° ë²ˆí˜¸ë³„ ì¶œí˜„ ë¹ˆë„
            for num in range(1, 46):
                features[f'freq_{num}'] = all_numbers.count(num)
            
            # 2. í†µê³„ íŠ¹ì„±
            features['mean'] = np.mean(all_numbers)
            features['std'] = np.std(all_numbers)
            features['median'] = np.median(all_numbers)
            
            # 3. í™€ì§ ë¹„ìœ¨
            odd_count = sum(1 for n in all_numbers if n % 2 == 1)
            features['odd_ratio'] = odd_count / len(all_numbers)
            
            # 4. ë²ˆí˜¸ ë²”ìœ„ ë¶„í¬
            low_count = sum(1 for n in all_numbers if n <= 15)
            mid_count = sum(1 for n in all_numbers if 16 <= n <= 30)
            high_count = sum(1 for n in all_numbers if n >= 31)
            features['low_ratio'] = low_count / len(all_numbers)
            features['mid_ratio'] = mid_count / len(all_numbers)
            features['high_ratio'] = high_count / len(all_numbers)
            
            # 5. ì—°ì† ë²ˆí˜¸ ê°œìˆ˜
            sorted_nums = sorted(all_numbers)
            consecutive = 0
            for i in range(len(sorted_nums)-1):
                if sorted_nums[i+1] - sorted_nums[i] == 1:
                    consecutive += 1
            features['consecutive'] = consecutive
            
            features_list.append(features)
            
            # íƒ€ê²Ÿ ê°’ (ë‹¤ìŒ íšŒì°¨ ë²ˆí˜¸)
            current = df.iloc[idx]
            for i in range(6):
                targets[f'num{i+1}'].append(current[f'number{i+1}'])
        
        X = pd.DataFrame(features_list)
        y = pd.DataFrame(targets)
        
        print(f"âœ“ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {X.shape[0]}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ íŠ¹ì„±")
        
        return X, y
    
    def train_random_forest(self, X, y):
        """Random Forest ëª¨ë¸ í•™ìŠµ"""
        print("\nğŸŒ² Random Forest ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        # ê° ë²ˆí˜¸ ìœ„ì¹˜ë³„ë¡œ ë³„ë„ ëª¨ë¸ í•™ìŠµ
        for i in range(1, 7):
            print(f"  - {i}ë²ˆì§¸ ë²ˆí˜¸ ëª¨ë¸ í•™ìŠµ ì¤‘...")
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y[f'num{i}'], test_size=0.2, random_state=42
            )
            
            # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            model.fit(X_train, y_train)
            
            # í‰ê°€
            train_score = model.score(X_train, y_train)
            test_score = model.score(X_test, y_test)
            
            print(f"    í•™ìŠµ ì •í™•ë„: {train_score:.3f}, í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_score:.3f}")
            
            self.rf_models[f'num{i}'] = model
        
        print("âœ“ Random Forest ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    def train_xgboost(self, X, y):
        """XGBoost ëª¨ë¸ í•™ìŠµ (íšŒê·€ ë°©ì‹)"""
        print("\nâš¡ XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        for i in range(1, 7):
            print(f"  - {i}ë²ˆì§¸ ë²ˆí˜¸ ëª¨ë¸ í•™ìŠµ ì¤‘...")
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y[f'num{i}'], test_size=0.2, random_state=42
            )
            
            # íšŒê·€ ëª¨ë¸ë¡œ ë³€ê²½ (ë¡œë˜ ë²ˆí˜¸ëŠ” 1~45 ë²”ìœ„ì˜ ì—°ì†ê°’)
            model = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42,
                n_jobs=-1
            )
            model.fit(X_train, y_train)
            
            # í‰ê°€ (RÂ² ìŠ¤ì½”ì–´)
            train_score = model.score(X_train, y_train)
            test_score = model.score(X_test, y_test)
            
            # RMSE ê³„ì‚°
            from sklearn.metrics import mean_squared_error
            train_pred = model.predict(X_train)
            test_pred = model.predict(X_test)
            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
            test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))
            
            print(f"    RÂ² ìŠ¤ì½”ì–´: {test_score:.3f}, RMSE: {test_rmse:.2f}")
            
            self.xgb_models[f'num{i}'] = model
        
        print("âœ“ XGBoost ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    def save_models(self):
        """ëª¨ë¸ ì €ì¥"""
        print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Random Forest ëª¨ë¸ ì €ì¥
        rf_path = os.path.join(self.models_dir, f'random_forest_{timestamp}.pkl')
        with open(rf_path, 'wb') as f:
            pickle.dump(self.rf_models, f)
        print(f"âœ“ Random Forest ëª¨ë¸ ì €ì¥: {rf_path}")
        
        # XGBoost ëª¨ë¸ ì €ì¥
        xgb_path = os.path.join(self.models_dir, f'xgboost_{timestamp}.pkl')
        with open(xgb_path, 'wb') as f:
            pickle.dump(self.xgb_models, f)
        print(f"âœ“ XGBoost ëª¨ë¸ ì €ì¥: {xgb_path}")
        
        # ìµœì‹  ëª¨ë¸ë¡œ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„±
        rf_latest = os.path.join(self.models_dir, 'random_forest_latest.pkl')
        xgb_latest = os.path.join(self.models_dir, 'xgboost_latest.pkl')
        
        if os.path.exists(rf_latest):
            os.remove(rf_latest)
        if os.path.exists(xgb_latest):
            os.remove(xgb_latest)
        
        os.symlink(os.path.basename(rf_path), rf_latest)
        os.symlink(os.path.basename(xgb_path), xgb_latest)
        
        print("âœ“ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
    
    def train_all(self):
        """ì „ì²´ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("=" * 70)
        print("  ğŸ¤– ë¡œë˜ ì˜ˆì¸¡ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("=" * 70)
        
        # 1. ë°ì´í„° ë¡œë“œ
        df = self.load_data(min_rounds=100)
        if df is None:
            return False
        
        # 2. íŠ¹ì„± ì¶”ì¶œ
        X, y = self.extract_features(df, window=10)
        
        # 3. Random Forest í•™ìŠµ
        self.train_random_forest(X, y)
        
        # 4. XGBoost í•™ìŠµ
        self.train_xgboost(X, y)
        
        # 5. ëª¨ë¸ ì €ì¥
        self.save_models()
        
        print("\n" + "=" * 70)
        print("  ğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        print("=" * 70)
        print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        print("  1. ëª¨ë¸ì„ ml-prediction ì„œë¹„ìŠ¤ì— ì ìš©")
        print("  2. API ì„œë²„ ì¬ì‹œì‘")
        print("  3. ì˜ˆì¸¡ API í…ŒìŠ¤íŠ¸")
        print()
        
        return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # DB ì—°ê²°
    db = Database(
        host=os.getenv('MYSQL_HOST', 'localhost'),
        user=os.getenv('MYSQL_USER', 'lotto_user'),
        password=os.getenv('MYSQL_PASSWORD', '2323'),
        database=os.getenv('MYSQL_DATABASE', 'lotto_db')
    )
    
    # í›ˆë ¨ ì‹œì‘
    trainer = LottoModelTrainer(db)
    success = trainer.train_all()
    
    if success:
        print("âœ… ì„±ê³µ!")
        sys.exit(0)
    else:
        print("âŒ ì‹¤íŒ¨!")
        sys.exit(1)


if __name__ == '__main__':
    main()
